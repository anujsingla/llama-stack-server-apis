llama-stack-client==0.2.20
requests==2.31.0
python-dotenv==1.0.0
rich==13.7.0
fastapi==0.104.1
uvicorn==0.24.0
tavily-python==0.3.3